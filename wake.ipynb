{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language Processing *Finnegans Wake*\n",
    "====================\n",
    "\n",
    "Below we will explore some tools in the [Python Natural Language Tool Kit](http://www.nltk.org/) and see what we can reveal of what might be a shameful choice of a warke.\n",
    "\n",
    "If you're new to *Finnegans Wake* I'll do my best to explain some of the things I'm trying to examine.\n",
    "\n",
    "Motivation\n",
    "---------------------\n",
    "When James Joyce published his infamous work of obliterature, *Finnegans Wake*, he wanted \"to keep the critics busy for 300 years\".\n",
    "\n",
    "It's been 75 years so maybe and some [Viconian thunderclaps](http://www.yourepeat.com/watch/?v=a11DEFm0WCw&start_at=347&end_at=390) later. We have new media through which we can clarify some of the obscurity of *The Wake*.\n",
    "\n",
    "Drawbacks\n",
    "---------------------\n",
    "There are admittedly drawbacks to textual analysis of *Finnegans Wake*. Principally that *The Wake* is meant to be [read out loud](https://www.youtube.com/watch?v=M8kFqiv8Vww). There's information, double, triple,..., Nth-le meaning, that's revealed when heard aloud. We're not gonna access that information heare, nor will we be able to pick up puns.\n",
    "\n",
    "Getting Started\n",
    "---------------------\n",
    "First we import the python libraries we'll be using and the text of Finnegans Wake itself.\n",
    "\n",
    "Note: If you're having difficulty getting these running on your machine, I recommend checking out Anaconda for OSX, which handles python package installs relatively cleanly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'finnegans', u'wake', u',', u'by', u'james', u'joyce', u'i', u'riverrun', u',', u'past', u'eve', u'and', u'adam\\u2019s', u',', u'from', u'swerve', u'of', u'shore', u'to', u'bend', u'of', u'bay', u',', u'brings', u'us', u'by', u'a', u'commodius', u'vicus', u'of', u'recirculation', u'back', u'to', u'howth', u'castle', u'and', u'environs', u'.', u'sir', u'tristram', u',', u'violer', u'd\\u2019amores', u',', u'fr\\u2019over', u'the', u'short', u'sea', u',', u'had']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "\n",
    "# Plotting library\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot graphs within ipython notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Python Natural Language Tool Kit\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Import Regular Expressions\n",
    "import re\n",
    "\n",
    "# Define a function to import and tokenize a book from a filename,\n",
    "# Return a tuple of FULL_TEXT, TOKENIZED_TEXT\n",
    "def import_text(path):\n",
    "    full_text = open(path).read().decode('utf8')\n",
    "    tokenized_text = nltk.Text(word_tokenize(full_text))\n",
    "    tokenized_text = [w.lower() for w in tokenized_text]\n",
    "    return full_text, tokenized_text\n",
    "\n",
    "# Import Finnegans Wake and create token list\n",
    "wake, wake_tokens = import_text(\"res/wake.txt\")\n",
    "\n",
    "# Print to make sure we have only lowercase text and no punctuation tokens\n",
    "print(wake_tokens[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary Richness\n",
    "---------------------\n",
    "First things first, lets see just how linguistically rich *Finnegans Wake* is. A popular metric for vocabulary richness is ratio of unique words to total words. We'll define a function that takes a text title and its tokens and returns its richness ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======FINNEGANS WAKE======\n",
      "Number of total words: 258468\n",
      "Number of unique words: 58629\n",
      "Ratio of unique to total: 0.226832722039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def richness(title, tokens):\n",
    "    total_words = len(tokens)\n",
    "    print (\"======\" + title.upper() + \"======\")\n",
    "    print (\"Number of total words: \" + str(total_words))\n",
    "    total_unique_words = len(set(tokens))\n",
    "    print (\"Number of unique words: \" + str(total_unique_words))\n",
    "    richness_ratio = total_unique_words / total_words\n",
    "    print (\"Ratio of unique to total: \" + str(richness_ratio) + \"\\n\")\n",
    "    \n",
    "richness(\"Finnegans Wake\", wake_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, 22.7% for a 258,468-word book.\n",
    "\n",
    "Let's see that ratio for 250,000-words worth of Herman Melville' *Moby Dick* and James Joyce's *Ulysses*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======ULYSSES======\n",
      "Number of total words: 319471\n",
      "Number of unique words: 30399\n",
      "Ratio of unique to total: 0.0951541767484\n",
      "\n",
      "======MOBY DICK======\n",
      "Number of total words: 250542\n",
      "Number of unique words: 18413\n",
      "Ratio of unique to total: 0.073492667896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Ulysses and create token list\n",
    "ulysses, ulysses_tokens = import_text(\"res/ulysses.txt\")\n",
    "\n",
    "# Import Moby Dick and create token list\n",
    "mobydick, mobydick_tokens = import_text(\"res/mobydick.txt\")\n",
    "\n",
    "richness(\"Ulysses\", ulysses_tokens)\n",
    "richness(\"Moby Dick\", mobydick_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ulysses* has 9.5% richness for a similar amount of words.\n",
    "\n",
    "*Moby Dick* has 7.3% richness for a similar amount of words.\n",
    "\n",
    "22.7% means *Finnegans Wake* is incredibly rich.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HCE and ALP\n",
    "---------------------\n",
    "Hundreds of characters appear in *Finnegans Wake* but all of those characters are actually just manifestations or sub-manifestations of man and woman, husband and wife, mountain and river, space and time. Joyce calls them HCE and ALP.\n",
    "\n",
    "Let's list all the different occurances of the initials HCE and ALP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Haroun Childeric Eggeberth\n",
      " he calmly extensolies.\n",
      " Hic cubat edilis.\n",
      " How Copen-hagen ended.\n",
      " happinest childher everwere.\n",
      "\n",
      "How charmingly exquisite!\n",
      " Hither, craching eastuards,\n",
      " Hag Chivychas Eve,\n",
      " Here Comes Everybody.\n",
      " Habituels conspicuously emergent.\n",
      " H. C. Earwicker\n",
      " he clearly expressed\n",
      " H. C. Earwicker,\n",
      " He’ll Cheat E’erawan\n",
      " haardly creditable edventyres\n",
      " haughty, cacuminal, erubescent\n",
      " Humpheres Cheops Exarchas,\n",
      " huge chain envelope,\n",
      " Hatches Cocks’ Eggs,\n",
      " haught crested elmer,\n",
      " his corns either.\n",
      " highly commendable exercise,\n",
      " high chief evervirens\n",
      " H2 C E3\n",
      " hagious curious encestor\n",
      " had claimed endright,\n",
      " Howforhim chirrupeth evereach-\n",
      " Homo Capite Erectus,\n",
      " He Can Explain,\n",
      " Howke Cotchme Eye,\n",
      " Huffy Chops Eads,\n",
      " hardily curio-sing entomophilust\n",
      " heptagon crystal emprisoms\n",
      " Hwang Chang evelytime;\n",
      " hoveth chieftains evrywehr,\n",
      " hereditatis columna erecta,\n",
      " hagion chiton eraphon;\n",
      " hallucination, cauchman, ectoplasm;\n",
      " hard cash earned\n",
      " Hewitt Castello, Equerry,\n",
      " heavengendered, chaosfoedted, earthborn;\n",
      " H. C. Endersen\n",
      " Henressy Crump Expolled,\n",
      " Huges Caput Earlyfouler.\n",
      " Her Chuff Exsquire!\n",
      " her calamity electrifies\n",
      " Hircus Civis Eblanensis!\n",
      " he can eyespy\n",
      " heather cliff emurgency\n",
      " Howarden’s Castle, Englandwales.\n",
      " Hulker’s cieclest elbownunsense.\n",
      " Housefather calls enthreateningly.\n",
      " human chain extends,\n",
      " Hocus Crocus, Esquilocus,\n",
      " his chthonic exterior\n",
      "\n",
      "Hoo cavedin earthwight\n",
      " Haud certo ergo.\n",
      "\n",
      "Honour commercio’s energy\n",
      "\n",
      "helm coverchaf emblem\n",
      " hce che ech,\n",
      " habby cyclic erdor\n",
      " his craft ebbing,\n",
      " hof cullchaw end\n",
      " Hengler’s Circus Entertainment,\n",
      " harbour craft emittences,\n",
      " harmonic condenser enginium\n",
      " Howe cools Eavybrolly!\n",
      " Heave, coves, emptybloddy!\n",
      " hero chief explunderer\n",
      " her changeable eye\n",
      " Hermyn C. Entwhistle)\n",
      " His Cum-bulent Embulence,\n",
      " how comes ever\n",
      " heaviest corpsus exemption)\n",
      " hugon come er-\n",
      "\n",
      "Horkus chiefest ebblynuncies!\n",
      " Hence counsels Ecclesiast.\n",
      " Hung Chung Egglyfella\n",
      " hulm culms evurdyburdy.\n",
      " Hang coersion everyhow!\n",
      " hear, Caller Errin!)\n",
      " highly continental evenements,\n",
      " him, com-pound eyes\n",
      " His Christian’s Em?\n",
      " Here Com-merces Enville.\n",
      " Helpless Corpses Enactment.\n",
      " home cooking every-time.\n",
      " home cured emigrant\n",
      " he could ever\n",
      " Hunkalus Childared Easterheld.\n",
      " his coglionial expancian?\n",
      " him circuly. Evovae!\n",
      " Hodie casus esobhrakonton?\n",
      " hugger-knut cramwell energuman,\n",
      " Hotchkiss Culthur’s Everready,\n",
      " his comfy estably\n",
      " Human Conger Eel!\n",
      " Ho, croak, evildoer!\n",
      " handshakey congrandyoulikethems, ecclesency.\n",
      " Haveth Childers Every\n",
      " Hery Crass Evohodie.\n",
      " her chastener ever\n",
      " huge Chesterfield elms\n",
      " Holiday, Christmas, Easter\n",
      " Horsehem coughs enough.\n",
      " heathen church emergency\n",
      " Hecklar’s champion ethnicist.\n",
      " Herenow chuck english\n",
      " Heinz cans everywhere\n",
      " huskiest coaxing experimenter\n",
      " Humpfrey, champion emir,\n",
      " hugest commercial emporialist,\n",
      " honoured christmastyde easteredman.\n",
      " horned cairns erge,\n",
      " hailed chimers’ ersekind;\n",
      " holiday crowd encounter;\n",
      " hullow chyst ex-cavement;\n",
      " Homos Circas Elochlannensis!\n",
      " Hagiographice canat Ecclesia.\n",
      " Hump cumps Ebblybally!\n",
      "\n",
      "Health, chalce, endnessnessessity!\n",
      " hophaz-ards can effective\n",
      " helpyourselftoastrool cure’s easy.\n",
      " hardest crux ever.\n"
     ]
    }
   ],
   "source": [
    "hce = re.findall(\"\\s[Hh]\\S*\\s[Cc]\\S*\\s[Ee]\\S*\", wake, re.U)\n",
    "for occurance in hce:\n",
    "    print(occurance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " askes lay. Phall\n",
      " addle liddle phifie\n",
      " Apud libertinam parvulam\n",
      " a lugly parson\n",
      " along landed Paddy\n",
      " a lady pack\n",
      " a lilyth, pull\n",
      " annie lawrie promises\n",
      " a lady’s postscript:\n",
      " arboro, lo petrusu.\n",
      " A Laugh-able Party,\n",
      " at length presuaded\n",
      " a lane picture\n",
      " Any lucans, please?\n",
      " acta legitima plebeia,\n",
      " any luvial peatsmoor\n",
      " Annos longos patimur\n",
      " and leadlight panes.\n",
      " areyou looking-for Pearlfar\n",
      " Amy Licks Porter\n",
      " and lited, pleaded\n",
      " a lovely park,\n",
      " are lovely, pitounette,\n",
      " and lice, pricking\n",
      " Amnis Limina Permanent)\n",
      " any lively purliteasy:\n",
      " a lunger planner’s\n",
      " a little present\n",
      " a loose past.\n",
      " and Le PŠre\n",
      " Annushka Lutetiavitch Pufflovah,\n",
      " All Ladies’ presents.\n",
      " and letters play\n",
      " apes. Lights, pageboy,\n",
      " alla ludo poker\n",
      " an litlee plads\n",
      " af liefest pose,\n",
      " AND LIBERTINE. PROPE\n",
      " a lonely peggy,\n",
      " appia lippia pluvaville,\n",
      " Art, literature, politics,\n",
      " American Lake Poetry,\n",
      " a luckybock, pledge\n",
      " Anna Lynchya Pourable\n",
      " anny livving plusquebelle,\n",
      " annapal livibel prettily\n",
      " a locally person\n",
      " a lyncheon partyng\n",
      " Aquasancta Liffey Patrol\n",
      " and last pre-electric\n",
      " Auld Letty Plussiboots\n",
      " and Luse polkas,\n",
      " and love potients\n",
      " artis litterarum-que patrona\n",
      " Anna Lynsha’s Pekoe\n",
      " Annabella, Lovabella, Pullabella,\n",
      " asseveralation. Ladiegent, pals\n",
      " a libidous pickpuckparty\n",
      " and Lorencz Pattorn\n",
      " Appia Lippia Pluviabilla,\n",
      " Annshee lispes privily.\n",
      " ambling limfy peepingpartner,\n",
      " all ladies please\n",
      " a lady!) pulling\n",
      "\n",
      "Alma Luvia, Pollabella.\n",
      " As leisure paces.\n",
      " A lintil pea.\n"
     ]
    }
   ],
   "source": [
    "alp = re.findall(\"\\s[Aa]\\S*\\s[Ll]\\S*\\s[Pp]\\S*\", wake, re.U)\n",
    "for occurance in alp:\n",
    "    print(occurance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurances of HCE: 124\n",
      "Number of occurances of ALP: 67\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of occurances of HCE: \" + str(len(hce)))\n",
    "print(\"Number of occurances of ALP: \" + str(len(alp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Queen's English\n",
    "---------------------\n",
    "*Finnegans Wake* seems inscrutable but many Joyceans say that the best guide to the wake is just a comprehensive English dictionary. Let's see just how many words in Finnegans are actually in English.\n",
    "\n",
    "We'll import a list of English words then see if we can find each word in that English word list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of English words to total words: 0.659849575189\n"
     ]
    }
   ],
   "source": [
    "# Import a list of all English Words\n",
    "en_words, eng_words_tokens = import_text('res/en-words.txt')\n",
    "\n",
    "#ENG_WAKE is the full text of Finnegans Wake with all non-English words removed\n",
    "eng_wake = [w for w in wake_tokens if w.lower() in eng_words_tokens]\n",
    "eng_ratio = len(eng_wake) / len(wake_tokens)\n",
    "print(\"Ratio of English words to total words: \" + str(eng_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So only 66% of the words in *Finnegans Wake* are valid (in the dictionary) English words.\n",
    "\n",
    "That above computation is pretty nasty though. Because it relies on a next for-loop it runs in O(n^2) time.\n",
    "\n",
    "We have a set of unique words from above. Let's just use set intersection to check quickly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of unique English words to total unique words: 0.324583397295\n"
     ]
    }
   ],
   "source": [
    "# ENG_WAKE_SET is a list of every unique English word in Finnegans Wake\n",
    "wake_tokens_set =  set(wake_tokens)\n",
    "eng_wake_set = list(set(eng_words_tokens) & wake_tokens_set)\n",
    "unique_eng_ratio = len(eng_wake_set) / len(wake_tokens_set)\n",
    "print(\"Ratio of unique English words to total unique words: \" + str(unique_eng_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of all the different words that occur in *Finnegans Wake* only 32.5% of those words are plain English!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Languages\n",
    "---------------------\n",
    "*Finnegans Wake* may be written mostly in plain English. There are many non-english words as well. Many of those words are constructed by Joyce himself, English or multi-lingual puns and portmanteaus. Although *The Wake* uses many Languages. For this first section we're going to concern ourselves with only words that exist in six of the most popular languages in *The Wake*: English, Irish, Latin, French, German and Italian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
